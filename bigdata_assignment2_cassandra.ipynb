{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in c:\\users\\amr01\\anaconda3\\lib\\site-packages (3.25.0)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\amr01\\anaconda3\\lib\\site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\amr01\\anaconda3\\lib\\site-packages (from cassandra-driver) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\amr01\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\amr01\\anaconda3\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25.0\n"
     ]
    }
   ],
   "source": [
    "import cassandra; print (cassandra.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0.6816\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "cloud_config= {\n",
    "        'secure_connect_bundle': 'C:/Users/amr01/Downloads/secure-connect-ass22.zip'\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider('vouDifKrZeEqtKJiuPDIOFRU', 'jQz8KSd0aZN9mqH1ywQ6KTZSgg6lFv1nqRZwn3CtDOOt6HmXZF92ihzXBAGZky8bEtxlw_.v8-E_70EufJefMLlSehwN.7q7f02zh5gOiZxgyIvT-MJYKiZlji21d_7H')\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()\n",
    "\n",
    "row = session.execute(\"select release_version from system.local\").one()\n",
    "if row:\n",
    "    print(row[0])\n",
    "else:\n",
    "    print(\"An error occurred.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('D:/computer science GIU/semester 6/BigData/GIU_2718_56_7524_2022-05-17T10_13_53/datasets/taxi_trip_data.csv',nrows = 2000,parse_dates=[\"pickup_datetime\", \"dropoff_datetime\"])\n",
    "df_geo = pd.read_csv('D:/computer science GIU/semester 6/BigData/GIU_2718_56_7524_2022-05-17T10_13_53/datasets/taxi_zone_geo.csv',nrows = 2000)\n",
    "i,j = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggregates': {},\n",
      " 'durable_writes': True,\n",
      " 'functions': {},\n",
      " 'graph_engine': None,\n",
      " 'indexes': {},\n",
      " 'name': 'ass2',\n",
      " 'replication_strategy': <cassandra.metadata.NetworkTopologyStrategy object at 0x000001732B3D7220>,\n",
      " 'tables': {'ass2': <cassandra.metadata.TableMetadataV3 object at 0x000001732B3D76D0>},\n",
      " 'user_types': {},\n",
      " 'views': {}}\n"
     ]
    }
   ],
   "source": [
    "session.set_keyspace('ass2')\n",
    "row = cluster.metadata.keyspaces['ass2']\n",
    "from pprint import pprint\n",
    "pprint(vars(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1732b47f7c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"\"\"\n",
    "    create table if not exists ass2.ass2 (\n",
    "        vendor_id text,\n",
    "        pickup_datetime datetime,\n",
    "        dropoff_datetime datetime,\n",
    "        passenger_count int,\n",
    "        trip_distance float,\n",
    "         \n",
    "        payment_type text,\n",
    "        fare_amount float,\n",
    "        extra float,\n",
    "        mta_tax float,\n",
    "        tip_amount float,\n",
    "        tolls_amount float,\n",
    "        imp_surcharge float,\n",
    "        pickup_location_id text,\n",
    "        dropoff_location_id text,\n",
    "        trip_id int,\n",
    "        Primary key (vendor_id)\n",
    "     );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,1000):\n",
    "    session.execute(\"insert into ass2.ass2(vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,imp_surcharge,pickup_location_id,dropoff_location_id) values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\",\n",
    "    (\n",
    "        str(df.loc[x].vendor_id),\n",
    "        str(df.loc[x].pickup_datetime),\n",
    "        str(df.loc[x].dropoff_datetime),\n",
    "        int(df.loc[x].passenger_count),\n",
    "        float(df.loc[x].trip_distance),\n",
    "        str(df.loc[x].payment_type),\n",
    "        float(df.loc[x].fare_amount),\n",
    "        float(df.loc[x].extra),\n",
    "        float(df.loc[x].mta_tax), \n",
    "        float(df.loc[x].tip_amount),\n",
    "        float(df.loc[x].tolls_amount), \n",
    "        float(df.loc[x].imp_surcharge),\n",
    "        str(df.loc[x].pickup_location_id), \n",
    "        str(df.loc[x].dropoff_location_id) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rows = session.execute(\"select * from ass2.ass2 limit 1\")\n",
    "for rows in show_rows:\n",
    "    print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"ALTER TABLE ass2.ass2 add duration float;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x250a2a327c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"ALTER TABLE ass2.ass2  DROP id;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = session.execute(\" select * from ass2.ass2 \")\n",
    "for c in row:\n",
    "    duration = (c[1]-c[10]).seconds/60\n",
    "    session.execute(\"update ass2.ass2 set duration = {0} where vendor_id='{1}';\".format(duration,c[0]))\n",
    "    print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"ALTER TABLE ass2.ass2 add total_cost float;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = session.execute(\"select * from ass2.ass2 \")\n",
    "for c in row:\n",
    "    total_cost = (c[5] + c[4] + c[7] + c[12] + c[13] + c[6])\n",
    "    session.execute(\"update ass2.ass2 set total_cost = {0} where vendor_id='{1}';\".format(total_cost,c[0]))\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tip=[]\n",
    "for i in range(2000): \n",
    "    if(df['passenger_count'][i]==1):\n",
    "        avg_tip1 = df['tip_amount'][i].mean()\n",
    "    if(df['passenger_count'][i]==2):\n",
    "        avg_tip2 = df['tip_amount'][i].mean()\n",
    "    if(df['passenger_count'][i]==3):\n",
    "        avg_tip3 = df['tip_amount'][i].mean()\n",
    "    if(df['passenger_count'][i]==4):\n",
    "        avg_tip4 = df['tip_amount'][i].mean()\n",
    "    if(df['passenger_count'][i]==5):\n",
    "        avg_tip5 = df['tip_amount'][i].mean()\n",
    "    if(df['passenger_count'][i]==6):\n",
    "        avg_tip6 = df['tip_amount'][i].mean()\n",
    "avg_tip=[avg_tip1,avg_tip2,avg_tip3,avg_tip4,avg_tip5,avg_tip6]\n",
    "avg_tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning = []\n",
    "afternoon = []\n",
    "evening = []\n",
    "for i in range (0, 2000):\n",
    "    if(df.loc[i].pickup_datetime.hour >= 5 and df.loc[i].pickup_datetime.hour < 12):\n",
    "        morning.append(df.iloc[i]['payment_type'])\n",
    "    if(df.loc[i].pickup_datetime.hour >= 12 and df.loc[i].pickup_datetime.hour < 17):\n",
    "        afternoon.append(df.iloc[i]['payment_type'])\n",
    "    if (df.loc[i].pickup_datetime.hour>= 17 and df.loc[i].pickup_datetime.hour < 21):\n",
    "            evening.append(df.iloc[i]['payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array(morning)\n",
    "unique, counts = np.unique(a, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(afternoon)\n",
    "unique, counts = np.unique(a, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(evening)\n",
    "unique, counts = np.unique(a, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_location_id'].nlargest(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "spark.sql(\"select zone_id,zone_name,COUNT(*) as num_trip from cassandratest2.cassandratest GROUP BY zone_id,zone_name \").show(5)\n",
    "spark.sql(\"SELECT time_day,payment_type,COUNT(*) as num_trips FROM cassandratest2.cassandratest GROUP BY time_day,payment_type \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3527085169292babaad897172dec52829b21678f2892aa21d59361c53edd25e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
